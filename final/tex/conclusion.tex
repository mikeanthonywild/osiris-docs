\chapter{Conclusion and further work}



\section{Summary}
In Chapter 1 we introduced the problem of existing cameras not being full-modular because of their fixed image sensors, and suggested that the problem was exasperated by the fact that image sensor \glspl{ic} implement their own proprietary interfaces, preventing interoperability. Finally we proposed that to be able to interface the camera with any image sensor, a piece of glue logic would be required to translate from the image sensor's proprietary interface to the standardised interface presented here.

The background concepts needed to understand the design of this standardised interface were explained in Chapter 2. The fundamental workings of an \gls{fpga} were conveyed, and we highlighted their suitability due to reconfigurability and high throughput. We also briefly detail how \glspl{cfa} and demosaicing are used to generate full-colour images from RAW image data.

In Chapter 3 we detailed some of the problems associated with high-speed data transmission and explored the industry shift towards serial interfaces and the various techniques and design considerations that go with it. Leading on from this, we examined several existing high-speed video interfaces and summarised their suitability as an image sensor interface, highlighting key shortcomings in several related to licensing requirements and complexity. Finally we settled on \gls{dvi}, citing a combination of attractive open licensing and simplicity.

Having justified basing the sensor interface on \gls{dvi}, we thoroughly explained the \gls{dvi} 1.0 specification in Chapter 4. After detailing the format of the data and how it is transmitted, we went on to suggest various additions, such as using \gls{edid} to store sensor capability information, which would make the interface better suited for image sensors.

Chapter 5 introduced the key components of the proof-of-concept system and discussed their design and the various hurdles encountered. 

Finally, in Chapter 6 we took the design discussed prior and tested various aspects such as reliable throughput and image integrity and concluded that the interface was mainly suitable for use with image sensors, but had more general issues which increased the complexity of implementation.

\section{Future work}

\subsection{Embedded Linux}

Xilinx's standalone FAT filesystem drivers, while sufficient for capturing still images from the low-resolution OV7670, lack the performance necessary for real-time high-definition video storage. The Linux kernel used for testing flash write speeds showed that the SD card and SDIO peripheral controller are capable of much higher speeds when not bottlenecked by slow filesystem drivers. Linux was considered for the base of the project, however it was rejected on the grounds that the memory protection would add too much complexity, as any interaction with the \gls{pl} would require low-level drivers to be written. While this is an undesirable hurdle for a proof-of-concept system, writing proper drivers for all \gls{pl}--\gls{ps} interaction would greatly enhance the reliability as low-level code would be prevented from stamping over other---unrelated, but equally mission-critical---code.

Using Linux would also open up access to powerful image processing libraries such as OpenCV which could be used to enhance the viewscreen monitor with real-time image processing \cite{opencv}. Currently the viewscreen displays a greyscale Bayer image from the same unmodified framebuffer which is used for capture and flash storage. OpenCV could be used to de-mosaic the framebuffer in real-time to send to the viewscreen so the user has a full-colour preview to aid the composition process.

In conjunction with transitioning the firmware over to embedded Linux, a high-speed storage interface such as SATA could be added to support seamless capture of full-HD RAW video, which requires a substantially higher read speed. 

\subsection{Camera control}

As soon as the sensor module board is powered on the \gls{fpga} starts capturing data continuously. This is fine for video capture, however stills photography requires a much tighter control over when image exposure occurs, as the matter of milliseconds between consecutive frames when capturing continuously can make all the difference --- especially in high-speed photography which requires precise triggering. As the sensor module and camera body share a communications channel via \gls{ddc}, the sensor module can be made to trigger from the camera body. Inside the \gls{dvi} encoder on the sensor module are a set of registers which can be exposed over \gls{ddc}. The register set could be extended to include registers for starting and stopping capture. Although I\textsuperscript{2}C is a relatively slow interface in terms of data throughput, the latency is sufficient that it could provide quite an accurate trigger mechanism.

For the proof-of-concept the OV7670 image sensor was configured to perform automatic exposure, whereby the image sensor measures the incoming light and adjusts its exposure time to produce a well-balanced image, compensating for too much or too little light. Shutter speed (and by extension exposure time) is commonly adjusted to achieve a specific look; long exposures, for example, produce blur which emphasises any motion in the image. In a proper camera it is very important that the user has full control over the exact exposure time in order to get certain shots. The \gls{ddc} registers could be extended to expose these additional parameters.

\subsection{Custom PCBs}

The proof-of-concept system presented here is simply that --- a proof of concept. While the Digilent Zybo development boards accelerated the prototyping phase, their bulk and awkward placement of connectors make them ill-suited for a compact camera form-factor. Xilinx has a wealth of reference material detailing developing custom \glspl{pcb} for their \gls{fpga} parts, which could be used to spin a more compact prototype \gls{pcb} to be fit inside a protective housing. Miniaturising the design would make it considerably more portable, thus it could be used outside and effectively tested in a real-world environment.

\subsection{Stability over wide range of resolutions}

One of the characteristics of the adopted \gls{dvi} interface is a variable-frequency pixel clock. Unlike packetised protocols (such as Ethernet) which always operate at their maximum rate regardless of the data being sent, the \gls{dvi} line rate is directly proportional to the number of pixels being transmitted. While this simplifies some aspects of the design, it adds significant complications to the clock recovery and phase alignment logic --- two parts which are crucial to achieving maximum performance. Future improvements should test the feasibility of replacing \gls{dvi} with a fixed-rate, packet-based protocol similar to \gls{mipi}. Fixing the \gls{serdes} clock frequency would simplify the clock recovery logic as the input clock is known ahead of time, thus the exact \gls{pll} parameters can be chosen such that the \gls{vco} is safely within its operational range. Choosing a packetised interfacing of course has the additional overhead of a packet protocol, which would take significant re-engineering of the existing work. The flexibility from a packetised interface would outweigh the disadvantages as it would allow for multiple different packet types which makes adding custom image sensor extensions a lot easier.

Another alternative would be to retain the \gls{dvi} interface, but use the highest overall resolution permitted by the link bandwidth. Instead of varying the pixel clock, the blanking period could be adjusted to ensure a constant overall pixel count regardless of the image sensor resolution, thus fixing the pixel clock at a single frequency.

\section{Conclusion}

While the proof-of-concept system successfully demonstrates that \gls{dvi} can be used as the basis for a standardised image sensor interface, it highlighted some key shortcomings that raise questions as to its suitability, primarily with regards to successfully decoding a wide range of video resolutions. Certain workarounds, like varying the blanking period, are suggested which would resolve some of these issues. Despite these set-backs, a working system able to maintain \SI{2.99}{\giga\bit\per\second} was developed, proving that \gls{dvi} certainly has its merits. 

Ultimately, a fully-modular camera is something which depends heavily on economies of scale to work --- far outside the scope of this paper. Given that the interface is open however, and the source for the design is public, it is perfectly possible that the project can blossom with community involvement and perhaps one day produce a camera which is free from planned obsolescence.